#!/bin/bash
# Author: V. Kuznetsov, V. Zemleris
# Description: this script import DAS JS files into MongoDB
# User may setup DASMAPS_DIR, the location where DAS maps will be staged
# by default the update_mapping_db.js file will be used as main DAS map
# otherwise das_maps_dbs_prod.js will be copied to DASMAPS_DIR as
# update_mapping_db.js file

usage="Usage: das_js_import <DASMaps directory>"
if [ $# -ne 1 ]; then
    echo $usage
    exit 1
fi
if [ "$1" == "-h" ] || [ "$1" == "-help" ] || [ "$1" == "--help" ]; then
    echo $usage
    exit 1
fi

set -e

if [ -z $DAS_CONFIG ]; then
    echo "DAS_CONFIG environment is not set"
    exit 1
fi
DASROOT=`python -c "import DAS; print '/'.join(DAS.__file__.split('/')[:-1])"`
DASMAPS_DIR=$1
DASMAPS_FILE=$DASMAPS_DIR/update_mapping_db.js
METADATA_DIR=$DASMAPS_DIR/kws

# figure out MongoDB host/port used in DAS via das configuration
export DAS_MONGO_HOST=`python $DASROOT/tools/config_reader.py --mongo_host`
export DAS_MONGO_PORT=`python $DASROOT/tools/config_reader.py --mongo_port`

echo "##### DAS & KWS maps parameters #####"
echo "DASMAPS_DIR       : $DASMAPS_DIR"
echo "MONGODB_HOST      : $DAS_MONGO_HOST"
echo "MONGODB_PORT      : $DAS_MONGO_PORT"

# figure out which md5sum utility exists
MD5CMD=$(for cmd in md5 md5sum; do type $cmd >/dev/null 2>&1 && echo $cmd && break; done);

# Helper: Update and clean a MongoDB database(s) and its collections
# Parameters:
# 1: object_name
# 2-n: list of strings specifying db_collection  to be updated
#
# If the update scripts have changes this will happen:
# * call clean_${object_name}.js
# * import update_{db_col,..}.js files into mongodb
update_db()
{
  local obj="$1"
  local updates=${@:2}  # all subsequent params are the updates

  echo "update_db: $obj $updates"
  # calculate stamp over (possibly multiple) collection updates
  stamp=$(cd $DASMAPS_DIR && printf "%s\n" $updates | xargs -I{} $MD5CMD "update_{}.js")
  if [ -f ${DASMAPS_DIR}/${obj}-schema-stamp ]; then
      oldstamp=$(cat ${DASMAPS_DIR}/${obj}-schema-stamp 2>/dev/null)
  else
      oldstamp="0"
  fi

  #echo "stamp: $stamp  oldstamp: $oldstamp"
  if [ ! -f ${DASMAPS_DIR}/${obj}-schema-stamp ] || [ X"$oldstamp" != X"$stamp" ]; then
    set -e
    # this seem to exit with 0 even if DB being cleaned do not exist
    # still we have to check if clean script exists, in case of multiple collections...
    if [ -f ${DASMAPS_DIR}/clean_${obj}.js ]; then
        echo "Clean ${obj}"
        mongo --verbose --host "$DAS_MONGO_HOST" --port "$DAS_MONGO_PORT" ${DASMAPS_DIR}/clean_${obj}.js
    fi

    for entry in ${updates[@]}
    do
        db=$(echo ${entry} | cut -f1 -d_) coll=$(echo ${entry} | cut -f2- -d_)
        echo "Updating db: ${db} col: ${coll}"
        mongoimport --host "$DAS_MONGO_HOST" --port "$DAS_MONGO_PORT" --db ${db} --collection ${coll} --file ${DASMAPS_DIR}/update_${entry}.js
    done
    echo "$stamp" > ${DASMAPS_DIR}/${obj}-schema-stamp
    set +e
  else
    echo "- no changes needed."
  fi
}

# PREPARE THE UPDATES
# -------------------

# prepares main DAS data (DASMaps) for being imported to DB
prepare_das_db_update(){
    mkdir -p $DASMAPS_DIR
    rm -f $DASMAPS_DIR/*mapping*-schema-stamp
    rm -f $DASMAPS_DIR/*keylearning*-schema-stamp
    rm -f $DASMAPS_DIR/*inputvals*-schema-stamp
    if [ ! -f $DASMAPS_FILE ]; then
        cp -f $DASMAPS_DIR/das_maps_dbs_prod.js $DASMAPS_DIR/update_mapping_db.js
    fi
    cp -f $METADATA_DIR/update_keylearning_db.js $DASMAPS_DIR
    cp -f $METADATA_DIR/update_inputvals*.js $DASMAPS_DIR
}

# run the updates now
run_db_update(){
    update_db "mapping" "mapping_db"
    update_db "keylearning" "keylearning_db"
    update_db "inputvals" inputvals_{datatype,group,release,site,status,tier}_name
}

# Actions
prepare_das_db_update
run_db_update
